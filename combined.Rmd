---
title: "biostats_final_combined"
author: "Miao Fu"
date: "2023-12-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE,warning=FALSE)
library(tidyverse)
library(dplyr)
library(kableExtra)
library(knitr)
library(patchwork)
library(corrplot)
library(gtsummary)
library(tidyr)
library(leaps)
library(glmnet)
library(olsrr)
library(MASS)
library(caret)
library(modelr)
library(mgcv)
```

```{r}
# read datafile
df = read_csv("data/Project_1_data.csv") |> 
  janitor::clean_names() |>
  mutate(
    wkly_study_hours = ifelse(
      wkly_study_hours == "10-May", "5-10", wkly_study_hours)
  )|>
  na.omit()

# Transforming categorical variables to factors
df_transformed <- df |> 
  mutate(
    gender = as.factor(gender),
    ethnic_group = as.factor(ethnic_group),
    parent_educ = factor(parent_educ,
                         levels= c("some high school", "high school", "associate's degree", "some college", "bachelor's degree", "master's degree")),
    lunch_type = as.factor(lunch_type),
    test_prep = as.factor(test_prep),
    parent_marital_status = as.factor(parent_marital_status),
    practice_sport = factor(practice_sport,
                            levels = c("never", "sometimes", "regularly")),
    is_first_child = factor(is_first_child),
    transport_means = as.factor(transport_means),
    wkly_study_hours = factor(wkly_study_hours,
                              levels = c("< 5", "5-10", "> 10"))
  )

# converting categorical variable to numeric variables
df_num=df|>
  mutate(
    gender = as.numeric(factor(gender)),
    ethnic_group = as.numeric(factor(ethnic_group)),
    parent_educ = as.numeric(factor(
      parent_educ,levels= c("some high school", "high school", 
                            "associate's degree", "some college", 
                            "bachelor's degree", "master's degree"))),
    lunch_type = as.numeric(factor(lunch_type)), 
    test_prep = as.numeric(factor(test_prep)),
    parent_marital_status = as.numeric(factor(parent_marital_status)), 
    practice_sport = as.numeric(
      factor(practice_sport, levels = c("never", "sometimes", "regularly"))), 
    is_first_child = as.numeric(factor(is_first_child)),
    transport_means = as.numeric(as.factor(transport_means)),
     wkly_study_hours = as.numeric(factor(wkly_study_hours,
                              levels = c("< 5", "5-10", "> 10")))
  )
```

# Descriptive summary statistics for all variables 

Two table with summary information on the descriptive statistics of all variables are listed below. The frequency and percentage of each categories in each categorical variable is listed out. For each numeric variable, the table includes values of mean, median, standard deviation, minimum, maximum, Q1 and Q3 values. 
```{r, include=FALSE}
# categorical
sum_stats_cat = function(data) {
  results = list()
  
  for (col in colnames(data)) {
    freq_table = table(data[[col]])
    total = sum(freq_table)
    percentages = freq_table / total * 100
    
    results[[col]] = as.data.frame(cbind(freq_table, percentages))
    colnames(results[[col]])=c("count","percent")
  }
  
  return(results)
}

results_cat=df|>
  dplyr::select(-nr_siblings,-math_score,-reading_score,-writing_score)|>
  sum_stats_cat()

for (i in seq_along(results_cat)) {
  print(results_cat[[i]])
}

# numeric
sum_stats_numeric=function(x) {
  results=list()
  
  for (col in colnames(x)){
  table=tibble(
  mean=mean(x[[col]],na.rm=TRUE),
  median=median(x[[col]],na.rm=TRUE),
  sd=sd(x[[col]],na.rm=TRUE),
  minimum=min(x[[col]],na.rm=TRUE),
  maximum=max(x[[col]],na.rm=TRUE),
  q1=quantile(x[[col]], 0.25,na.rm=TRUE),
  q3=quantile(x[[col]], 0.75,na.rm=TRUE))

  results[[col]] = table
  }
  return(results)
}

results_num=df|>
  dplyr::select(nr_siblings,math_score,reading_score,writing_score)|>
  sum_stats_numeric()


```

## Categorical Variables
```{r,echo=FALSE}
do.call(rbind, results_cat)|>
  rownames_to_column(var="variable")|>
  separate(variable,into=c("variable","category"),sep="\\.")|>
  knitr::kable()
```

## Numeric Variables
```{r,echo=FALSE}
do.call(rbind, results_num)|>
  rownames_to_column(var = "variable")|>
  knitr::kable()
```

# Exploration of outcome variables

The outcome of this study includes the following variables: maths scores, reading scores, and writing scores. QQplots of the outcome variables are created to explore the distribution of each score. QQplot compares the quantiles of the data against the quantiles of  a normal distribution. According the plots, majority of the data points of all three scores follow the straight qqline, which indicates they follow the normal distribution. However, there are some deviations from the line on the two ends of the distribution, which indicates the distributions might have heavier tails than normal distribution. To further explore the distribution of outcomes, histograms and boxplots for the scores were incorporated. They are slightly left-tailed but mainly normally distributed. Thus, transformations are tested in the later section to further investigate the variables. 

```{r,echo=FALSE}

# qqplots of 3 scores
qq_math=df|>
  ggplot(aes(sample = math_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for maths score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

qq_writing=df|>
  ggplot(aes(sample = writing_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for writing score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

qq_reading=df|>
  ggplot(aes(sample = reading_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for reading score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

(qq_math+qq_reading)/qq_writing

# distribution for 3 scores

maths_hist=df|>
  dplyr::select(math_score)|>
  ggplot(aes(x=(math_score)))+
  geom_histogram()+
  labs(
    x="Maths Score",
    y="Count"
  )

maths_box=df|>
  dplyr::select(math_score)|>
  ggplot(aes(x=(math_score)))+
  geom_boxplot()+
  labs(
    x="Maths Score"
  )

reading_hist=df|>
  dplyr::select(reading_score)|>
  ggplot(aes(x=(reading_score)))+
  geom_histogram()+
  labs(
    x="Reading Score",
    y="Count"
  )

reading_box=df|>
  dplyr::select(reading_score)|>
  ggplot(aes(x=(reading_score)))+
  geom_boxplot()+
  labs(
    x="Reading Score"
  )

writing_hist=df|>
  dplyr::select(writing_score)|>
  ggplot(aes(x=(writing_score)))+
  geom_histogram()+
  labs(
    x="Writing Score",
    y="Count"
  )

writing_box=df|>
  dplyr::select(writing_score)|>
  ggplot(aes(x=(writing_score)))+
  geom_boxplot()+
  labs(
    x="Writing Score"
  )

(maths_hist+maths_box)/(reading_hist+reading_box)/(writing_hist+writing_box)
```

# Exploration of predictor variables

```{r}
par(mfrow=c(2,3))
barplot(table(df_transformed$gender), main='Gender')
barplot(table(df_transformed$ethnic_group), main='Ethnic Group')
barplot(table(df_transformed$lunch_type), main='Lunch Type')
barplot(table(df_transformed$test_prep), main='Test Prep')
barplot(table(df_transformed$parent_educ), main='Parent Education')
barplot(table(df_transformed$parent_marital_status), main='Parent Marital Status')
barplot(table(df_transformed$practice_sport), main='Practice Sports')
barplot(table(df_transformed$is_first_child), main='First Child')
barplot(table(df_transformed$nr_siblings), main='Siblings')
barplot(table(df_transformed$transport_means), main='Transport Means')
barplot(table(df_transformed$wkly_study_hours), main='Weekly Study Hours')

```
From the distribution bar graphs, it was decided that no transformation is needed for any predictor variables. Admittedly, the distributions might not be good references for transformation because the variables are all categorical. 

# Potential transformations for outcome variables 

```{r}
# Log, Sqrt, and Inverse transformation of outcomes
df_eda=df|>
  dplyr::select(math_score,writing_score,reading_score)|>
  mutate(
    lgMath=log(math_score),
    sqMath=sqrt(math_score),
    inMath=1/(math_score),
    lgRead=log(reading_score),
    sqRead=sqrt(reading_score),
    inRead=1/(reading_score),
    lgWrite=log(writing_score),
    sqWrite=sqrt(writing_score),
    inWrite=1/(writing_score),
  )
par(mfrow=c(2,3))
hist(df_eda$lgMath, main="Log(Maths Score)",xlab="Score")
hist(df_eda$sqMath, main="sq(Maths Score)",xlab="Score")
hist(df_eda$inMath, main="in(Maths Score)",xlab="Score")
hist(df_eda$lgRead, main="Log(Reading Score)",xlab="Score")
hist(df_eda$sqRead, main="sq(Reading Score)",xlab="Score")
hist(df_eda$inRead, main="in(Reading Score)",xlab="Score")
hist(df_eda$lgWrite, main="Log(Writing Score)",xlab="Score")
hist(df_eda$sqWrite, main="sq(Writing Score)",xlab="Score")
hist(df_eda$inWrite, main="in(Writing Score)",xlab="Score")

```
Since the distribution of the three scores showed slightly left-tailed, three types of transformations were tested: 1) Natural logarithm 2) Square Root 3) Inverse. The resulting plots are plotted in histograms shown above. There is no apparent improvement on the distribution of the outcome through the three transformations. Thus, the orignial outcome data were chosen to be used in following statistical modeling steps. 

# Pairwise relationships

```{r}
df_num|>
  cor()|>
  corrplot(type = "upper", diag = FALSE)
```

By plotting our the pairwise correlation between variables, there is apparent linearity among the three scores. Other correlation coefficients are relatively small, indicating weak linear relationship between the variables. 

# MLR lm()

```{r MLR models}
# Build the MLR model for Math scores
model_math <- lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)
model_read <- lm(reading_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)
model_write <- lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)


```


## MLR - Math
```{r math}
summary(model_math)
```

### Coefficients and Significance Levels:
* Intercept (44.1006): The expected value of math_score when all other predictors are at their reference level or zero.
* gendermale (5.0855, p < 0.001): Being male is associated with an average increase of 5.0855 points in math_score compared to females, holding all else constant. This is statistically significant.
* ethnic_group: Only ethnic_groupgroup E (11.1752, p < 0.001) is significant, suggesting students in this group score higher in math compared to the reference group.
* parent_educ: The associate's degree (4.9058, p = 0.00584), bachelor's degree (6.6652, p = 0.00140), and master's degree (6.8096, p = 0.00760) are significant and associated with higher math scores compared to the reference category.
* lunch_typestandard (12.3539, p < 0.001): Students with standard lunch type score significantly higher.
* test_prepnone (-4.7717, p < 0.001): Not participating in test preparation is associated with lower math scores.
* parent_marital_status: Married (5.4805, p = 0.00075) and Widowed (7.7944, p = 0.04134) are associated with higher scores.
* practice_sport: Not significant.
* is_first_childyes: Not significant.
* nr_siblings (0.7403, p = 0.05461): A borderline significant positive association with math scores.
* transport_meansschool_bus: Not significant.
* wkly_study_hours: Studying 5-10 hours (3.5394, p = 0.00863) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
Residual Standard Error (13.52): Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* Multiple R-squared (0.3221): About 32.21% of the variability in math_score is explained by the model.
* Adjusted R-squared (0.2956): Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
F-statistic (12.18) and p-value (< 2.2e-16): The model is statistically significant, meaning it performs better than a model with no predictors.

## MLR - reading
```{r}
summary(model_read)
```
### Coefficients and Significance Levels:
* **Intercept (60.8028)**: The expected value of `reading_score` when all other predictors are at their reference level or zero.
* **gendermale (-7.6725, p < 0.001)**: Being male is associated with an average decrease of 7.6725 points in `reading_score` compared to females, holding all else constant. This is statistically significant.
* **ethnic_group**: Only `ethnic_groupgroup E` (5.9165, p = 0.013402) is significant, suggesting students in this group score higher in reading compared to the reference group.
* **parent_educ**: The `associate's degree` (4.7948, p = 0.005776), `bachelor's degree` (7.3496, p = 0.000313), and `master's degree` (8.7149, p = 0.000479) are significant and associated with higher reading scores compared to the reference category.
* **lunch_typestandard (8.4374, p < 0.001)**: Students with standard lunch type score significantly higher.
* **test_prepnone (-6.2822, p < 0.001)**: Not participating in test preparation is associated with lower reading scores.
* **parent_marital_statusmarried (5.2439, p = 0.000950)**: Children of married parents score higher.
* **practice_sport**: Not significant.
* **is_first_childyes**: Not significant.
* **nr_siblings (0.3882, p = 0.301309)**: No significant association with reading scores.
* **transport_meansschool_bus**: Not significant.
* **wkly_study_hours**: Studying 5-10 hours (2.6835, p = 0.041104) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
* **Residual Standard Error (13.2)**: Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* **Multiple R-squared (0.2709)**: About 27.09% of the variability in `reading_score` is explained by the model.
* **Adjusted R-squared (0.2425)**: Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
* **F-statistic (9.527)** and **p-value (< 2.2e-16)**: The model is statistically significant, meaning it performs better than a model with no predictors.

## MLR - writing
```{r}
summary(model_write) 
```
### Coefficients and Significance Levels:
* **Intercept (57.808758)**: The expected value of `writing_score` when all other predictors are at their reference level or zero.
* **gendermale (-9.268845, p < 0.001)**: Being male is associated with an average decrease of 9.268845 points in `writing_score` compared to females, holding all else constant. This is statistically significant.
* **ethnic_group**: `ethnic_groupgroup D` (5.010576, p = 0.016531) and `ethnic_groupgroup E` (6.018419, p = 0.008673) are significant, suggesting students in these groups score higher in writing compared to the reference group.
* **parent_educ**: `associate's degree` (6.130783, p = 0.000239), `some college` (4.338798, p = 0.010898), `bachelor's degree` (9.217680, p = 2.62e-06), and `master's degree` (11.712279, p = 1.10e-06) are significant and associated with higher writing scores compared to the reference category.
* **lunch_typestandard (9.390698, p < 0.001)**: Students with standard lunch type score significantly higher.
* **test_prepnone (-8.754351, p < 0.001)**: Not participating in test preparation is associated with lower writing scores.
* **parent_marital_statusmarried (5.246610, p = 0.000561)**: Children of married parents score higher.
* **practice_sport**: Not significant.
* **is_first_childyes**: Not significant.
* **nr_siblings (0.546033, p = 0.129340)**: No significant association with writing scores.
* **transport_meansschool_bus**: Not significant.
* **wkly_study_hours**: Studying 5-10 hours (2.802323, p = 0.026048) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
* **Residual Standard Error (12.65)**: Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* **Multiple R-squared (0.3634)**: About 36.34% of the variability in `writing_score` is explained by the model.
* **Adjusted R-squared (0.3385)**: Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
* **F-statistic (14.63)** and **p-value (< 2.2e-16)**: The model is statistically significant, meaning it performs better than a model with no predictors.


## Cleaned datasets - updated by Nisha
```{r}
set.seed(555)

step_df = read_csv("data/Project_1_data.csv") |>
  drop_na() |> janitor::clean_names() |>
  mutate(
    wkly_study_hours = ifelse(
      wkly_study_hours == "10-May", "5-10", wkly_study_hours)
  )|>
  mutate(
    gender = as.integer(factor(gender)),
    ethnic_group = as.integer(factor(ethnic_group)),
    parent_educ = as.integer(factor(
      parent_educ,levels= c("some high school", "high school", 
                            "associate's degree", "some college", 
                            "bachelor's degree", "master's degree"))),
    lunch_type = as.integer((factor(lunch_type))), 
    test_prep = as.integer((factor(test_prep))),
    parent_marital_status = as.integer((factor(parent_marital_status))), 
    practice_sport = as.integer((factor(practice_sport, levels = c("never", "sometimes", "regularly")))), 
    is_first_child = as.integer((factor(is_first_child))),
    transport_means = as.integer((factor(transport_means))),
     wkly_study_hours = as.integer((factor(wkly_study_hours,
                              levels = c("< 5", "5-10", "> 10"))))
  )

math_df = dplyr::select(step_df, -c(reading_score, writing_score)) 

reading_df = dplyr::select(step_df, -c(math_score, writing_score))

writing_df = dplyr::select(step_df, -c(reading_score, math_score))
```

## Step-wise: Backwards Elimination

Math Score
```{r}
mult.fit = lm(math_score ~ ., data = math_df)
summary(mult.fit)

# No Transport Means
step1 = update(mult.fit, . ~ . -transport_means)
summary(step1)

# No Is First Child
step2 = update(step1, . ~ . -is_first_child)
summary(step2)

# No Practice Sport
step3 = update(step2, . ~ . -practice_sport)
summary(step3)

# No Parent Marital Status
step4 = update(step3, . ~ . -parent_marital_status)
summary(step4)

# No Number of Siblings
math_backward_manual_fit = update(step4, . ~ . -nr_siblings)
summary(math_backward_manual_fit)
fin = summary(math_backward_manual_fit)

# just use one function
math_backward_func_fit = step(mult.fit, direction='backward')
one_fun_fin = summary(math_backward_func_fit)
```
With manual elimination, the model we obtained was Math Score ~ Gender + Ethnic
Group + Parent Education + Lunch Type + Test Prep + Weekly Study Hours.

When using the single-function method, the model obtained with the lowest AIC
was Math Score ~ Gender + Ethnic Group + Parent Education + Lunch Type + 
Test Prep + Number of Siblings + Weekly Study Hours. Both models' MSEs are 
within 0.5 points of each other, while the single function had a lower MSE by
about 1 point.


Reading Score
```{r}
mult.fit = lm(reading_score ~ ., data = reading_df)
summary(mult.fit)

# No Parent Marital Status
step1 = update(mult.fit, . ~ . -parent_marital_status)
summary(step1)

# No Is First Child
step2 = update(step1, . ~ . -is_first_child)
summary(step2)

# No Transport Means
step3 = update(step2, . ~ . -transport_means)
summary(step3)

# No Number of Siblings
step4 = update(step3, . ~ . -nr_siblings)
summary(step4)

# No Practice Sport
step5 = update(step4, . ~ . -practice_sport)
summary(step5)

# No Weekly Study Hours
reading_backward_manual_fit = update(step5, . ~ . -wkly_study_hours)
fin = summary(reading_backward_manual_fit)
fin

# just use one function
reading_backward_func_fit = step(mult.fit, direction='backward')
one_fun_fin = summary(reading_backward_func_fit)
```
With manual elimination, the model we obtained was Reading Score ~ Gender + Ethnic
Group + Parent Education + Lunch Type + Test Prep.

When using the single-function method, the model obtained with the lowest AIC
was Reading Score ~ Gender + Ethnic Group + Parent Education + Lunch Type + 
Test Prep. The one-function model had a lower MSE than the manually-calculated
model by about 14 points and a higher R-sqaured value by about 10 points.

Writing Score
```{r}
mult.fit = lm(writing_score ~ ., data = writing_df)
summary(mult.fit)

# No Is First Child
step1 = update(mult.fit, . ~ . -is_first_child)
summary(step1)

# No Practice Sport
step2 = update(step1, . ~ . -practice_sport)
summary(step2)

# No Transport Means
step3 = update(step2, . ~ . -transport_means)
summary(step3)

# No Parent Marital Status
step4 = update(step3, . ~ . -parent_marital_status)
summary(step4)

# No Number of Siblings
step5 = update(step4, . ~ . -nr_siblings)
summary(step5)

# No Weekly Study Hours
writing_backward_manual_fit = update(step5, . ~ . -wkly_study_hours)
fin = summary(writing_backward_manual_fit)

# just use one function
writing_backward_func_fit = step(mult.fit, direction='backward')
one_fun_fin = summary(writing_backward_func_fit)
```
With manual elimination, the model we obtained was Writing Score ~ Gender + Ethnic
Group + Parent Education + Lunch Type + Test Prep.

When using the single-function method, the model obtained with the lowest AIC
was Writing Score ~ Gender + Ethnic Group + Parent Education + Lunch Type + 
Test Prep + Weekly Study Hours. Both models had equal R-squared values and MSEs 
within 0.6 points of each other.

## Step-wise: Forward Elimination

Math Score
```{r}

mult.fit = lm(math_score ~ ., data = math_df)

### Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
fit1 = lm(math_score ~ gender, data = step_df)
summary(fit1)
fit2 = lm(math_score ~ ethnic_group, data = step_df)
summary(fit2)
fit3 = lm(math_score ~ parent_educ, data = step_df)
summary(fit3)
fit4 = lm(math_score ~ lunch_type, data = step_df)
summary(fit4)
fit5 = lm(math_score ~ parent_marital_status, data = step_df)
summary(fit5)
fit6 = lm(math_score ~ practice_sport, data = step_df)
summary(fit6)
fit7 = lm(math_score ~ is_first_child, data = step_df)
summary(fit7)
fit8 = lm(math_score ~ nr_siblings, data = step_df)
summary(fit8)
fit9 = lm(math_score ~ transport_means, data = step_df)
summary(fit9)
fit10 = lm(math_score ~ wkly_study_hours, data = step_df)
summary(fit10)
fit11 = lm(math_score ~ test_prep, data = step_df)
summary(fit11)

# Enter first the one with the lowest p-value: Lunch Type
forward1 = lm(math_score ~ lunch_type, data = step_df)
first = summary(forward1)|> broom::tidy()


### Step 2: Enter the one with the lowest p-value in the rest 
fit1 = update(forward1, . ~ . +gender)
summary(fit1)

fit2 = update(forward1, . ~ . +ethnic_group)
summary(fit2)

fit3 = update(forward1, . ~ . +parent_educ)
summary(fit3)

fit4 = update(forward1, . ~ . +parent_marital_status)
summary(fit4)

fit5 = update(forward1, . ~ . +practice_sport)
summary(fit5)

fit6 = update(forward1, . ~ . +is_first_child)
summary(fit6)

fit7 = update(forward1, . ~ . +nr_siblings)
summary(fit7)

fit8 = update(forward1, . ~ . +transport_means)
summary(fit8)

fit9 = update(forward1, . ~ . +wkly_study_hours)
summary(fit9)

fit10 = update(forward1, . ~ . +test_prep)
summary(fit10)


# Enter the one with the lowest p-value: Ethnic Group
forward2 = update(forward1, . ~ . +ethnic_group)
summary(fit2)

### Step 3: Enter the one with the lowest p-value in the rest 
fit1 = update(forward2, . ~ . +gender)
summary(fit1)

fit2 = update(forward2, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward2, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward2, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward2, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward2, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward2, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward2, . ~ . +wkly_study_hours)
summary(fit8)

fit9 = update(forward2, . ~ . +test_prep)
summary(fit9)


# Enter the one with the lowest p-value: Test Prep
forward3 = update(forward2, . ~ . + test_prep)
summary(forward3)

### Step 4: Enter the one with the lowest p-value in the rest 
fit1 = update(forward3, . ~ . +gender)
summary(fit1)

fit2 = update(forward3, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward3, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward3, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward3, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward3, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward3, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward3, . ~ . +wkly_study_hours)
summary(fit8)


# Enter the one with the lowest p-value: Gender
forward4 = update(forward3, . ~ . + gender)
summary(forward4)

### Step 5: Enter the one with the lowest p-value in the rest 
fit1 = update(forward4, . ~ . +parent_educ)
summary(fit1)

fit2 = update(forward4, . ~ . +parent_marital_status)
summary(fit2)

fit3 = update(forward4, . ~ . +practice_sport)
summary(fit3)

fit4 = update(forward4, . ~ . +is_first_child)
summary(fit4)

fit5 = update(forward4, . ~ . +nr_siblings)
summary(fit5)

fit6 = update(forward4, . ~ . +transport_means)
summary(fit6)

fit7 = update(forward4, . ~ . +wkly_study_hours)
summary(fit7)

# Enter the one with the lowest p-value: Parent Education
forward5 = update(forward4, . ~ . + parent_educ)
summary(forward5)

### Step 6: Enter the one with the lowest p-value in the rest 
fit1 = update(forward5, . ~ . +parent_marital_status)
summary(fit1)

fit2 = update(forward5, . ~ . +practice_sport)
summary(fit2)

fit3 = update(forward5, . ~ . +is_first_child)
summary(fit3)

fit4 = update(forward5, . ~ . +nr_siblings)
summary(fit4)

fit5 = update(forward5, . ~ . +transport_means)
summary(fit5)

fit6 = update(forward5, . ~ . +wkly_study_hours)
summary(fit6)


# Enter the one with the lowest p-value: Weekly Study Hours
forward6 = update(forward5, . ~ . + wkly_study_hours)
summary(forward6)

### Step 7: Enter the one with the lowest p-value in the rest 
fit1 = update(forward6, . ~ . +parent_marital_status)
summary(fit1)

fit2 = update(forward6, . ~ . +practice_sport)
summary(fit2)

fit3 = update(forward6, . ~ . +is_first_child)
summary(fit3)

fit4 = update(forward6, . ~ . +nr_siblings)
summary(fit4)

fit5 = update(forward6, . ~ . +transport_means)
summary(fit5)


# P-value of all new added variables are larger than 0.05, which means that they 
# are not significant predictor, and we stop here.

math_forward_manual_fit = lm(math_score ~ lunch_type + ethnic_group + test_prep + 
    gender + parent_educ + wkly_study_hours, data = step_df)
fin = summary(math_forward_manual_fit)

# fit using one function
intercept_only <- lm (math_score ~ 1, data = math_df)
math_forward_func_fit = step(intercept_only, direction = "forward", scope = formula(mult.fit))
one_fun_fin = summary(math_forward_func_fit)
```
The model we obtained is Math Score ~ Lunch Type + Ethnic Group + Test Prep +
Gender + Parent Education + Weekly Study Hours.

When using the single-function method, the model obtained with the lowest AIC
was Math Score ~ Lunch Type + Ethnic Group + Test Prep + Gender + Parent
Education + Weekly Study Hours + Number of Siblings. This method resulted in a
model that had a slightly lower MSE by a difference of about 1 point and
approximately the same R-squared/Adjusted R-squared values.


Reading Score
```{r}
mult.fit = lm(reading_score ~ ., data = reading_df)

### Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
fit1 = lm(reading_score ~ gender, data = step_df)
summary(fit1)
fit2 = lm(reading_score ~ ethnic_group, data = step_df)
summary(fit2)
fit3 = lm(reading_score ~ parent_educ, data = step_df)
summary(fit3)
fit4 = lm(reading_score ~ lunch_type, data = step_df)
summary(fit4)
fit5 = lm(reading_score ~ parent_marital_status, data = step_df)
summary(fit5)
fit6 = lm(reading_score ~ practice_sport, data = step_df)
summary(fit6)
fit7 = lm(reading_score ~ is_first_child, data = step_df)
summary(fit7)
fit8 = lm(reading_score ~ nr_siblings, data = step_df)
summary(fit8)
fit9 = lm(reading_score ~ transport_means, data = step_df)
summary(fit9)
fit10 = lm(reading_score ~ wkly_study_hours, data = step_df)
summary(fit10)
fit11 = lm(reading_score ~ test_prep, data = step_df)
summary(fit11)

# Enter first the one with the lowest p-value: Lunch Type
forward1 = lm(reading_score ~ lunch_type, data = step_df)
summary(forward1)


### Step 2: Enter the one with the lowest p-value in the rest 
fit1 = update(forward1, . ~ . +gender)
summary(fit1)

fit2 = update(forward1, . ~ . +ethnic_group)
summary(fit2)

fit3 = update(forward1, . ~ . +parent_educ)
summary(fit3)

fit4 = update(forward1, . ~ . +parent_marital_status)
summary(fit4)

fit5 = update(forward1, . ~ . +practice_sport)
summary(fit5)

fit6 = update(forward1, . ~ . +is_first_child)
summary(fit6)

fit7 = update(forward1, . ~ . +nr_siblings)
summary(fit7)

fit8 = update(forward1, . ~ . +transport_means)
summary(fit8)

fit9 = update(forward1, . ~ . +wkly_study_hours)
summary(fit9)

fit10 = update(forward1, . ~ . +test_prep)
summary(fit10)


# Enter the one with the lowest p-value: Gender
forward2 = update(forward1, . ~ . +gender)
summary(fit2)

### Step 3: Enter the one with the lowest p-value in the rest 
fit1 = update(forward2, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward2, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward2, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward2, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward2, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward2, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward2, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward2, . ~ . +wkly_study_hours)
summary(fit8)

fit9 = update(forward2, . ~ . +test_prep)
summary(fit9)


# Enter the one with the lowest p-value: Test Prep
forward3 = update(forward2, . ~ . + test_prep)
summary(forward3)

### Step 4: Enter the one with the lowest p-value in the rest 
fit1 = update(forward3, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward3, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward3, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward3, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward3, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward3, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward3, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward3, . ~ . +wkly_study_hours)
summary(fit8)


# Enter the one with the lowest p-value: Parent Education
forward4 = update(forward3, . ~ . + parent_educ)
summary(forward4)

### Step 5: Enter the one with the lowest p-value in the rest 
fit1 = update(forward4, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward4, . ~ . +parent_marital_status)
summary(fit2)

fit3 = update(forward4, . ~ . +practice_sport)
summary(fit3)

fit4 = update(forward4, . ~ . +is_first_child)
summary(fit4)

fit5 = update(forward4, . ~ . +nr_siblings)
summary(fit5)

fit6 = update(forward4, . ~ . +transport_means)
summary(fit6)

fit7 = update(forward4, . ~ . +wkly_study_hours)
summary(fit7)

# Enter the one with the lowest p-value: Ethnic Group
forward5 = update(forward4, . ~ . + ethnic_group)
summary(forward5)

### Step 6: Enter the one with the lowest p-value in the rest 
fit1 = update(forward5, . ~ . +parent_marital_status)
summary(fit1)

fit2 = update(forward5, . ~ . +practice_sport)
summary(fit2)

fit3 = update(forward5, . ~ . +is_first_child)
summary(fit3)

fit4 = update(forward5, . ~ . +nr_siblings)
summary(fit4)

fit5 = update(forward5, . ~ . +transport_means)
summary(fit5)

fit6 = update(forward5, . ~ . +wkly_study_hours)
summary(fit6)

# P-value of all new added variables are larger than 0.05, which means that they 
# are not significant predictor, and we stop here.

# The model we obtained is Reading Score ~ Lunch Type + Gender + Test Prep + 
# Parent Education + Ethnic Group

reading_forward_manual_fit = lm(reading_score ~ lunch_type + gender + test_prep + 
                      parent_educ + ethnic_group, data = step_df)
fin = summary(reading_forward_manual_fit)

# fit using one function
intercept_only <- lm (reading_score ~ 1, data = reading_df)
reading_forward_func_fit = step(intercept_only, direction = "forward", scope = formula(mult.fit))
one_fun_fin = summary(reading_forward_func_fit)

```
The model we obtained is Reading Score ~ Lunch Type + Gender + Test Prep + 
Parent Education + Ethnic Group.

When using the single-function method, the model obtained with the lowest AIC
was Reading Score ~ Lunch Type + Gender + Test Prep + Parent Education + 
Ethnic Group. Both models at equal MSE and R-sqaured values.

Writing Score
```{r}
mult.fit = lm(writing_score ~ ., data = writing_df)

### Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
fit1 = lm(writing_score ~ gender, data = step_df)
summary(fit1)
fit2 = lm(writing_score ~ ethnic_group, data = step_df)
summary(fit2)
fit3 = lm(writing_score ~ parent_educ, data = step_df)
summary(fit3)
fit4 = lm(writing_score ~ lunch_type, data = step_df)
summary(fit4)
fit5 = lm(writing_score ~ parent_marital_status, data = step_df)
summary(fit5)
fit6 = lm(writing_score ~ practice_sport, data = step_df)
summary(fit6)
fit7 = lm(writing_score ~ is_first_child, data = step_df)
summary(fit7)
fit8 = lm(writing_score ~ nr_siblings, data = step_df)
summary(fit8)
fit9 = lm(writing_score ~ transport_means, data = step_df)
summary(fit9)
fit10 = lm(writing_score ~ wkly_study_hours, data = step_df)
summary(fit10)
fit11 = lm(writing_score ~ test_prep, data = step_df)
summary(fit11)

# Enter first the one with the lowest p-value: Gender
forward1 = lm(writing_score ~ gender, data = step_df)
summary(forward1)


### Step 2: Enter the one with the lowest p-value in the rest 
fit1 = update(forward1, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward1, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward1, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward1, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward1, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward1, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward1, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward1, . ~ . +wkly_study_hours)
summary(fit8)

fit9 = update(forward1, . ~ . +test_prep)
summary(fit9)

fit10 = update(forward1, . ~ . +lunch_type)
summary(fit10)


# Enter the one with the lowest p-value: Lunch Type
forward2 = update(forward1, . ~ . +lunch_type)
summary(fit2)

### Step 3: Enter the one with the lowest p-value in the rest 
fit1 = update(forward1, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward1, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward1, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward1, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward1, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward1, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward1, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward1, . ~ . +wkly_study_hours)
summary(fit8)

fit9 = update(forward1, . ~ . +test_prep)
summary(fit9)

# Enter the one with the lowest p-value: Test Prep
forward3 = update(forward2, . ~ . + test_prep)
summary(forward3)

### Step 4: Enter the one with the lowest p-value in the rest 
fit1 = update(forward3, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward3, . ~ . +parent_educ)
summary(fit2)

fit3 = update(forward3, . ~ . +parent_marital_status)
summary(fit3)

fit4 = update(forward3, . ~ . +practice_sport)
summary(fit4)

fit5 = update(forward3, . ~ . +is_first_child)
summary(fit5)

fit6 = update(forward3, . ~ . +nr_siblings)
summary(fit6)

fit7 = update(forward3, . ~ . +transport_means)
summary(fit7)

fit8 = update(forward3, . ~ . +wkly_study_hours)
summary(fit8)


# Enter the one with the lowest p-value: Parent Education
forward4 = update(forward3, . ~ . + parent_educ)
summary(forward4)

### Step 5: Enter the one with the lowest p-value in the rest 
fit1 = update(forward4, . ~ . +ethnic_group)
summary(fit1)

fit2 = update(forward4, . ~ . +parent_marital_status)
summary(fit2)

fit3 = update(forward4, . ~ . +practice_sport)
summary(fit3)

fit4 = update(forward4, . ~ . +is_first_child)
summary(fit4)

fit5 = update(forward4, . ~ . +nr_siblings)
summary(fit5)

fit6 = update(forward4, . ~ . +transport_means)
summary(fit6)

fit7 = update(forward4, . ~ . +wkly_study_hours)
summary(fit7)

# Enter the one with the lowest p-value: Ethnic Group
forward5 = update(forward4, . ~ . + ethnic_group)
summary(forward5)

### Step 6: Enter the one with the lowest p-value in the rest 
fit1 = update(forward5, . ~ . +parent_marital_status)
summary(fit1)

fit2 = update(forward5, . ~ . +practice_sport)
summary(fit2)

fit3 = update(forward5, . ~ . +is_first_child)
summary(fit3)

fit4 = update(forward5, . ~ . +nr_siblings)
summary(fit4)

fit5 = update(forward5, . ~ . +transport_means)
summary(fit5)

fit6 = update(forward5, . ~ . +wkly_study_hours)
summary(fit6)

# P-value of all new added variables are larger than 0.05, which means that they 
# are not significant predictor, and we stop here.

# The model we obtained is Writing Score ~ Gender + Lunch Type + Test Prep +
# Parent Education + Ethnic Group

writing_forward_manual_fit = lm(writing_score ~ gender + lunch_type + test_prep + 
                      parent_educ + ethnic_group, data = step_df)
fin = summary(writing_forward_manual_fit)

# fit using one function
intercept_only <- lm (writing_score ~ 1, data = writing_df)
writing_forward_func_fit = step(intercept_only, direction = "forward", scope = formula(mult.fit))
one_fun_fin = summary(writing_forward_func_fit)
```
The model we obtained is Writing Score ~ Lunch Type + Ethnic Group + Test Prep +
Gender + Parent Education + Weekly Study Hours.

When using the single-function method, the model obtained with the lowest AIC
was Writing Score ~ Gender + Lunch Type + Test Prep + Parent Education + Ethnic
Group + Weekly Study Hours. Both models had R-squared values and MSEs within 0.6
points of each other.

It seems that when using the single-function method, for all scores and for both
forwards and backwards elimination, extra variables were included despite their 
individual p-values > 0.05; therefore the manually-selected models should be 
used for comparison and validation.

## Criteria-based approach - Adjusted R^2, Cp, BIC
(Note: BIC has a larger penalty, leading to less predictors present within 
the model.)

Math Score
```{r}
# perform best subset selection
best_subset <- regsubsets(math_score ~ ., math_df, nvmax = 11)
results <- summary(best_subset)

# extract and plot results
tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) |>
  gather(statistic, value, -predictors) |>
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")

results$which[7,]|>print()
math_criteria_fit = lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type+ test_prep + nr_siblings, wkly_study_hours, data = step_df)
```
To predict math score, the adjusted R^2 statistic, Cp, and BIC plots in combination show that a 7-variable model is optimal. 
The predictors selected are: gender, ethnic_group, parent_educ, lunch_type, test_prep, nr_siblings, and wkly study_hours. 

Reading Score
```{r}
best_subset <- regsubsets(reading_score ~ ., reading_df, nvmax = 11)
results <- summary(best_subset)

tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")

results$which[5,]|>print()
reading_criteria_fit = lm(reading_score ~ gender + ethnic_group + parent_educ + lunch_type+ test_prep, data = step_df)
```
To predict reading score, the adjusted R^2 statistic and Cp and BIC plots shows that a 5-variable model is optimal. 
The predictors selected are: gender, ethnic_group, parent_educ, lunch_type, test_prep. 

Writing Score
```{r}
best_subset <- regsubsets(writing_score ~ ., writing_df, nvmax = 11)
results <- summary(best_subset)

tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")

results$which[5,] |>print()
writing_criteria_fit = lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep, data = step_df)
```
To predict writing score, the adjusted R^2, Cp, and BIC statistics show that a 5-variable model is optimal. \
The predictors selected are: gender, ethnic_group, parent_educ, lunch_type, test_prep

Limitation: noting that the plots maximum and minimum are not that obvious.

## LASSO approach - 

Maths score:
```{r}
# Find the best lambda
math_lasso=step_df|>
  dplyr::select(-reading_score,-writing_score)|>
  dplyr::select(math_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(1)
cv_object = cv.glmnet(as.matrix(math_lasso[2:12]),math_lasso$math_score, lambda = lambda_seq, nfolds = 5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
math_model_lasso=glmnet(as.matrix(math_lasso[2:12]),math_lasso$math_score,lambda=cv_object$lambda.min)
coef(math_model_lasso)
```

Reading score:

```{r}
read_lasso=step_df|>
  dplyr::select(-math_score,-writing_score)|>
  dplyr::select(reading_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(2)
cv_object = cv.glmnet(as.matrix(read_lasso[2:12]),read_lasso$reading_score, lambda = lambda_seq, nfolds =5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
read_model_lasso=glmnet(as.matrix(read_lasso[2:12]),read_lasso$reading_score,lambda=cv_object$lambda.min)
coef(read_model_lasso)
```

Writing score:

```{r}
write_lasso=df_num|>
  dplyr::select(-reading_score,-math_score)|>
  dplyr::select(writing_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(2)
cv_object = cv.glmnet(as.matrix(write_lasso[2:12]),write_lasso$writing_score, lambda = lambda_seq, nfolds =5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
write_model_lasso=glmnet(as.matrix(write_lasso[2:12]),write_lasso$writing_score,lambda=cv_object$lambda.min)
coef(write_model_lasso)
```

# Cross Validation
Here are the summary of all the models that have been created in this project.
```{r}
# Clean out the variables used in stepwise analysis
var_names = step_df |> dplyr::select(!ends_with("score"))  |> colnames()

math_theoretical_fit = lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + nr_siblings + wkly_study_hours, data = step_df)

reading_theoretical_fit = lm(reading_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + wkly_study_hours, data = step_df)

writing_theoretical_fit = lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + wkly_study_hours, data = step_df)

models_report_df = rbind(
  math_theoretical_fit,
  math_backward_manual_fit,
  math_backward_func_fit,
  math_forward_manual_fit,
  math_forward_func_fit,
 reading_theoretical_fit,
  reading_backward_manual_fit,
  reading_backward_func_fit,
  reading_forward_manual_fit,
  reading_forward_func_fit,
  writing_theoretical_fit,
  writing_backward_manual_fit,
  writing_backward_func_fit,
  writing_forward_manual_fit,
  writing_forward_func_fit,
  math_criteria_fit,
  reading_criteria_fit,
  writing_criteria_fit)

models_report_df_rownames = models_report_df |> row.names()
models_report_df_colnames = models_report_df |> colnames()

models_report_df = models_report_df |> 
  as.data.frame() |>
  cbind(models_report_df_rownames) |>
  rename(model_name = models_report_df_rownames) |>
  dplyr::select( model_name, coefficients, terms) |>
  mutate(coefficients = map(coefficients, \(coef) map(coef, ~ "X"))) |>
  unnest_wider(coefficients) |>
  mutate(
    subject = map(model_name, \(i) str_extract(i, "^[:alpha:]+")),
    method = map(model_name, \(i) str_extract(i, "(?<=[:alpha:]_).+(?=_fit)"))
  ) |>
  dplyr::select(-model_name) |>
  relocate(subject,method, terms)

models_report_df |>
  dplyr::select(-terms) |>
  knitr::kable()%>%
kable_styling("striped", full_width = F) %>%
  row_spec(0, angle = -90)
```

We will be performing cross validation to select the best model resulted from the models above.

## Method from the lecture code
```{r}
set.seed(1)
# Use 5-fold validation and create the training sets
train = trainControl(method = "cv", number = 5)

cv_lecture_df = models_report_df |>
  dplyr::select(subject, method, terms) |>
  mutate(model = map(terms, \(formula) train(as.formula(formula),
                   data = step_df,
                   trControl = train,
                   method = 'lm',
                   na.action = na.pass)),
         model = map(model, \(i) i$finalModel),
         MSE = map(model, \(i) mean(i$residuals^2)))
```

## Method using crossv_mc
```{r warning=TRUE}
set.seed(1)
cv_ds_df = 
  modelr::crossv_mc(step_df, 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |>
  mutate(
    fits = map(train, \(i) cv_lecture_df |> transpose() |> as.list())) |>
  unnest(fits) |>
  unnest_wider(fits, strict = TRUE, names_repair = "minimal") |>
  mutate(
    cv_model = map2(train, terms, \(df, i) lm(as.formula(i), data = df)),
    cv_mse = map2(cv_model, test, \(mod, df) mse(model = mod, data = df)),
    cv_mse = as.numeric(cv_mse),
    method = as.character(method)
  )
```
Notice how `practice_sport` and `transport_means` are not selected in any of the model selections methods. This will be reported at the effect modifier section.

## Cross Validation - Math

### Method from the lecture codes
```{r}
math_caret_df = cv_lecture_df |>
  filter(subject == "math")

math_caret_df |>
  dplyr::select(method, MSE) |>
  knitr::kable()

math_caret_df = math_caret_df |>
  filter(MSE == min(math_caret_df$MSE |> unlist()))

# Only one value
math_best_fit = math_caret_df$model[[1]]
```
The model with the best MSE for Math is `r paste(math_caret_df$terms)`, which uses `r paste(math_caret_df$method)` as a method of approach.

### Method using crossv_mc
```{r}
cv_ds_df |> 
  filter(subject == "math") |> 
  group_by(method) |>
  ggplot(aes(x = method, y = cv_mse)) +
  geom_violin()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
```{r}
cv_ds_df |> 
  filter(subject == "math") |> 
  group_by(method) |>
  summarize(average_mse = mean(cv_mse)) |>
  knitr::kable()
```
We noticed that the the best model is the one that uses forward elimination with one line code and backward elimination with one line code. The model is `r models_report_df |> filter(subject == "math", method == "forward_func") |> pull(terms) |> paste()`

## Cross Validation - Reading

### Method from the lecture codes
```{r}
reading_caret_df = cv_lecture_df |>
  filter(subject == "reading")

reading_caret_df |>
  dplyr::select(method, MSE) |>
  knitr::kable()

reading_caret_df = reading_caret_df |>
  filter(MSE == min(reading_caret_df$MSE |> unlist()))

# Only one value
reading_best_fit = reading_caret_df$model[[1]]
```
The model with the best MSE for Reading is `r paste(reading_caret_df$terms)`, which uses `r paste(reading_caret_df$method)` as a method of approach.

### Method using crossv_mc
```{r}
cv_ds_df |> 
  filter(subject == "reading") |> 
  group_by(method) |>
  ggplot(aes(x = method, y = cv_mse)) +
  geom_violin()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
```{r}
cv_ds_df |> 
  filter(subject == "reading") |> 
  group_by(method) |>
  summarize(average_mse = mean(cv_mse)) |>
  knitr::kable()
```
We noticed that the the best model is the model that is picked by forward and backward elimination method and criterion based approach. The model is `r models_report_df |> filter(subject == "reading", method == "forward_func") |> pull(terms) |> paste()`

## Cross Validation - Writing
### Method from the lecture codes
```{r}
writing_caret_df = cv_lecture_df |>
  filter(subject == "writing")

writing_caret_df |>
  dplyr::select(method, MSE) |>
  knitr::kable()

writing_caret_df = writing_caret_df |>
  filter(MSE == min(writing_caret_df$MSE |> unlist()))

# Only one value
writing_best_fit = writing_caret_df$model[[1]]
```
The model with the best MSE for Writing is `r paste(writing_caret_df$terms)`, which uses `r paste(writing_caret_df$method)` as a method of approach.

### Method using crossv_mc
```{r warning=TRUE}
cv_ds_df |> 
  filter(subject == "writing") |> 
  group_by(method) |>
  ggplot(aes(x = method, y = cv_mse)) +
  geom_violin()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
```{r}
cv_ds_df |> 
  filter(subject == "writing") |> 
  group_by(method) |>
  summarize(average_mse = mean(cv_mse)) |>
  knitr::kable()
```
We noticed that the the best model is the one that uses forward elimination with one line code and backward elimination with one line code. The model is `r models_report_df |> filter(subject == "writing", method == "forward_func") |> pull(terms) |> paste()`

# Effect Modifier
We will take a logical approach to get the effect modification within the variables. 

* The variables provided to measure the scores are `r step_df |> dplyr::select(-ends_with("score")) |> colnames() |> paste(sep = ',')`. `is_first_child` and the `nr_siblings` can be related since if the person have no siblings, then the probability that they are the first child is 1. 

* If the person practice sports(`practice_sport`, then they are less likely to take the bus (`transport_means`) back to their location. 

* `gender`, `ethnic_group`, `parent_educ`, `parent_marital_status`, `transport_means` can all affect the person's family financial background. This can be reflected directly with `lunch_type`. We will only evaluate the effect of `gender`, `ethnic_group` on `lunch_type`.

* `practice_sport` can affect the `wkly_study_hours` as the sports will take up chunks of time to study.

The models that will be used in the effect modifier section are the models that are selected using `crossv_mc()` function, i.e.

`r models_report_df |> filter(subject == "math", method == "forward_func") |> pull(terms) |> paste()`

`r models_report_df |> filter(subject == "reading", method == "forward_func") |> pull(terms) |> paste()`

`r models_report_df |> filter(subject == "writing", method == "forward_func") |> pull(terms) |> paste()`

Here are the procedures for identifying effect modifiers and find confounders of the
Here are all the possible effect interactions if we load in all of the predictors. 
```{r}
lm(as.formula(str_c("math_score ~ ", paste(var_names, collapse = " * "))), data = step_df) |> 
  anova() |> 
  broom::tidy() |> 
  filter(str_detect(term, ":")) |>
  filter(p.value < 0.05) |>
  knitr::kable(digits = 3, caption = "Math: Effect Modifiers")
```
```{r}
lm(as.formula(str_c("reading_score ~ ", paste(var_names, collapse = " * "))), data = step_df) |> 
  anova() |> 
  broom::tidy() |> 
  filter(str_detect(term, ":")) |>
  filter(p.value < 0.05) |>
  knitr::kable(digits = 3, caption = "Reading: Effect Modifiers")
```
```{r}
lm(as.formula(str_c("writing_score ~ ", paste(var_names, collapse = " * "))), data = step_df) |> 
  anova() |> 
  broom::tidy() |> 
  filter(str_detect(term, ":")) |>
  filter(p.value < 0.05) |>
  knitr::kable(digits = 3, caption = "Writing: Effect Modifiers")
```
## Confounder
```{r}
# Math:
lm(as.formula(math_best_cv_terms), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Math: Original")

lm(as.formula(gsub("wkly_study_hours", "wkly_study_hours + practice_sport", math_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Math: Test if practice_sport is a confounder of wkly_study_hours")

# Writing
lm(as.formula(writing_best_cv_terms), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: Original")

lm(as.formula(gsub("wkly_study_hours", "wkly_study_hours + practice_sport", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: Test if practice_sport is a confounder of wkly_study_hours")
```
We will include the interaction terms that involves two predictors and see how they affect the models that we have selected in the cross validation sections.

```{r}
corr(
```
## Confounding - Math
```{r}
# Writing
lm(as.formula(writing_best_cv_terms), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: full under CV")

lm(as.formula(gsub("gender", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Gender")

lm(as.formula(gsub("lunch_type", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Lunch Type")

lm(as.formula(gsub("test_prep", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Test Prep")

lm(as.formula(gsub("\\+ parent_educ", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Parent Education")

lm(as.formula(gsub("ethnic_group", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Ethnic Group")

lm(as.formula(gsub("\\+ wkly_study_hours", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Weekly Study Hours")

lm(as.formula(gsub("\\+ wkly_study_hours", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Weekly Study Hours")
```

```{r}
lm(math_score ~ , data = step_df)|>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Weekly Study Hours")
```


## Confounding - Reading
```{r}
lm(as.formula(writing_best_cv_terms), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: full under CV")

lm(as.formula(gsub("gender", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Gender")

lm(as.formula(gsub("lunch_type", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Lunch Type")

lm(as.formula(gsub("test_prep", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Test Prep")

lm(as.formula(gsub("\\+ parent_educ", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Parent Education")

lm(as.formula(gsub("ethnic_group", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Ethnic Group")

lm(as.formula(gsub("\\+ wkly_study_hours", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Weekly Study Hours")
```


## Confounding - Writing
```{r}
# Writing
lm(as.formula(writing_best_cv_terms), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: full under CV")

lm(as.formula(gsub("gender", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Gender")

lm(as.formula(gsub("lunch_type", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Lunch Type")

lm(as.formula(gsub("test_prep", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Test Prep")

lm(as.formula(gsub("\\+ parent_educ", "", writing_best_cv_terms)), data = step_df) |> #
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Parent Education")

lm(as.formula(gsub("ethnic_group", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Ethnic Group")

lm(as.formula(gsub("\\+ wkly_study_hours", "", writing_best_cv_terms)), data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: without Weekly Study Hours")
```
We can see, removing `gender` will lower `wkly_study_hours` by `r abs(1.176-0.924)/1.176`, removing `test_prep` will lower `wkly_study_hours` by `r abs(1.176-1.792)/1.176`, and removing `parent_educ` will lower `wkly_study_hours` by `r abs(1.176-0.991)/1.176`.

Hence, `gender`, `test_prep`, `parent_educ` could be protential confounder for 

```{r}
abs(1.176-0.924)/1.176
abs(1.176-1.792)/1.176
abs(1.176-0.991)/1.176
```

```{r}
lm(writing_score ~ gender * test_prep * wkly_study_hours * parent_educ + ethnic_group + lunch_type, data = step_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3, caption = "Writing: with Number of Siblings")
```




# Leverage one score 

Since according to the corr plot, there are strong collinearity between the scores. We can just add one score (reading_score for example) to another score's model (maths_score for example) and see if the resulting model is improved. 



