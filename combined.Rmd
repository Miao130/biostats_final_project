---
title: "biostats_final_combined"
author: "Miao Fu"
date: "2023-12-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE,warning=FALSE)
library(tidyverse)
library(dplyr)
library(patchwork)
library(corrplot)
library(gtsummary)
library(tidyr)
library(leaps)
library(glmnet)
library(olsrr)
library(MASS)
library(caret)
```

```{r}
# read datafile
df = read_csv("data/Project_1_data.csv") |> 
  janitor::clean_names() |>
  mutate(
    wkly_study_hours = ifelse(
      wkly_study_hours == "10-May", "5-10", wkly_study_hours)
  )|>
  na.omit()

# Transforming categorical variables to factors
df_transformed <- df |> 
  mutate(
    gender = as.factor(gender),
    ethnic_group = as.factor(ethnic_group),
    parent_educ = factor(parent_educ,
                         levels= c("some high school", "high school", "associate's degree", "some college", "bachelor's degree", "master's degree")),
    lunch_type = as.factor(lunch_type),
    test_prep = as.factor(test_prep),
    parent_marital_status = as.factor(parent_marital_status),
    practice_sport = factor(practice_sport,
                            levels = c("never", "sometimes", "regularly")),
    is_first_child = factor(is_first_child),
    transport_means = as.factor(transport_means),
    wkly_study_hours = factor(wkly_study_hours,
                              levels = c("< 5", "5-10", "> 10"))
  )

# converting categorical variable to numeric variables
df_num=df|>
  mutate(
    gender = as.numeric(factor(gender)),
    ethnic_group = as.numeric(factor(ethnic_group)),
    parent_educ = as.numeric(factor(
      parent_educ,levels= c("some high school", "high school", 
                            "associate's degree", "some college", 
                            "bachelor's degree", "master's degree"))),
    lunch_type = as.numeric(factor(lunch_type)), 
    test_prep = as.numeric(factor(test_prep)),
    parent_marital_status = as.numeric(factor(parent_marital_status)), 
    practice_sport = as.numeric(
      factor(practice_sport, levels = c("never", "sometimes", "regularly"))), 
    is_first_child = as.numeric(factor(is_first_child)),
    transport_means = as.numeric(as.factor(transport_means)),
     wkly_study_hours = as.numeric(factor(wkly_study_hours,
                              levels = c("< 5", "5-10", "> 10")))
  )
```

# Descriptive summary statistics for all variables 

Two table with summary information on the descriptive statistics of all variables are listed below. The frequency and percentage of each categories in each categorical variable is listed out. For each numeric variable, the table includes values of mean, median, standard deviation, minimum, maximum, Q1 and Q3 values. 
```{r, include=FALSE}
# categorical
sum_stats_cat = function(data) {
  results = list()
  
  for (col in colnames(data)) {
    freq_table = table(data[[col]])
    total = sum(freq_table)
    percentages = freq_table / total * 100
    
    results[[col]] = as.data.frame(cbind(freq_table, percentages))
    colnames(results[[col]])=c("count","percent")
  }
  
  return(results)
}

results_cat=df|>
  dplyr::select(-nr_siblings,-math_score,-reading_score,-writing_score)|>
  sum_stats_cat()

for (i in seq_along(results_cat)) {
  print(results_cat[[i]])
}

# numeric
sum_stats_numeric=function(x) {
  results=list()
  
  for (col in colnames(x)){
  table=tibble(
  mean=mean(x[[col]],na.rm=TRUE),
  median=median(x[[col]],na.rm=TRUE),
  sd=sd(x[[col]],na.rm=TRUE),
  minimum=min(x[[col]],na.rm=TRUE),
  maximum=max(x[[col]],na.rm=TRUE),
  q1=quantile(x[[col]], 0.25,na.rm=TRUE),
  q3=quantile(x[[col]], 0.75,na.rm=TRUE))

  results[[col]] = table
  }
  return(results)
}

results_num=df|>
  dplyr::select(nr_siblings,math_score,reading_score,writing_score)|>
  sum_stats_numeric()


```

## Categorical Variables
```{r,echo=FALSE}
do.call(rbind, results_cat)|>
  rownames_to_column(var="variable")|>
  separate(variable,into=c("variable","category"),sep="\\.")|>
  knitr::kable()
```

## Numeric Variables
```{r,echo=FALSE}
do.call(rbind, results_num)|>
  rownames_to_column(var = "variable")|>
  knitr::kable()
```

# Exploration of outcome variables

The outcome of this study includes the following variables: maths scores, reading scores, and writing scores. QQplots of the outcome variables are created to explore the distribution of each score. QQplot compares the quantiles of the data against the quantiles of  a normal distribution. According the plots, majority of the data points of all three scores follow the straight qqline, which indicates they follow the normal distribution. However, there are some deviations from the line on the two ends of the distribution, which indicates the distributions might have heavier tails than normal distribution. Or, there might be skewness or outliers in the dataset. To further explore the distribution of outcomes, histograms and boxplots for the scores were incorporated. As suggested by the histograms and boxplots, all three scores are left-skewed with outliers on the left side of the distribution. 


```{r,echo=FALSE}

# qqplots of 3 scores
qq_math=df|>
  ggplot(aes(sample = math_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for maths score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

qq_writing=df|>
  ggplot(aes(sample = writing_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for writing score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

qq_reading=df|>
  ggplot(aes(sample = reading_score)) +
  stat_qq() +
  geom_qq_line()+
  ggtitle("QQ Plot for reading score") +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")

(qq_math+qq_reading)/qq_writing

# distribution for 3 scores

maths_hist=df|>
  dplyr::select(math_score)|>
  ggplot(aes(x=(math_score)))+
  geom_histogram()+
  labs(
    x="Maths Score",
    y="Count"
  )

maths_box=df|>
  dplyr::select(math_score)|>
  ggplot(aes(x=(math_score)))+
  geom_boxplot()+
  labs(
    x="Maths Score"
  )

reading_hist=df|>
  dplyr::select(reading_score)|>
  ggplot(aes(x=(reading_score)))+
  geom_histogram()+
  labs(
    x="Reading Score",
    y="Count"
  )

reading_box=df|>
  dplyr::select(reading_score)|>
  ggplot(aes(x=(reading_score)))+
  geom_boxplot()+
  labs(
    x="Reading Score"
  )

writing_hist=df|>
  dplyr::select(writing_score)|>
  ggplot(aes(x=(writing_score)))+
  geom_histogram()+
  labs(
    x="Writing Score",
    y="Count"
  )

writing_box=df|>
  dplyr::select(writing_score)|>
  ggplot(aes(x=(writing_score)))+
  geom_boxplot()+
  labs(
    x="Writing Score"
  )

(maths_hist+maths_box)/(reading_hist+reading_box)/(writing_hist+writing_box)
```

# Exploration of predictor variables

```{r}
par(mfrow=c(2,3))
barplot(table(df_transformed$gender), main='Gender')
barplot(table(df_transformed$ethnic_group), main='Ethnic Group')
barplot(table(df_transformed$lunch_type), main='Lunch Type')
barplot(table(df_transformed$test_prep), main='Test Prep')
barplot(table(df_transformed$parent_educ), main='Parent Education')
barplot(table(df_transformed$parent_marital_status), main='Parent Marital Status')
barplot(table(df_transformed$practice_sport), main='Practice Sports')
barplot(table(df_transformed$is_first_child), main='First Child')
barplot(table(df_transformed$nr_siblings), main='Siblings')
barplot(table(df_transformed$transport_means), main='Transport Means')
barplot(table(df_transformed$wkly_study_hours), main='Weekly Study Hours')

```
From the distribution bar graphs. It looks like no transformation is needed for any predictor variables.

# Potential transformations 

```{r}
# Log, Sqrt, and Inverse transformation of outcomes
df_eda=df|>
  dplyr::select(math_score,writing_score,reading_score)|>
  mutate(
    lgMath=log(math_score),
    sqMath=sqrt(math_score),
    inMath=1/(math_score),
    lgRead=log(reading_score),
    sqRead=sqrt(reading_score),
    inRead=1/(reading_score),
    lgWrite=log(writing_score),
    sqWrite=sqrt(writing_score),
    inWrite=1/(writing_score),
  )
par(mfrow=c(2,3))
hist(df_eda$lgMath, main="Log(Maths Score)",xlab="Score")
hist(df_eda$sqMath, main="sq(Maths Score)",xlab="Score")
hist(df_eda$inMath, main="in(Maths Score)",xlab="Score")
hist(df_eda$lgRead, main="Log(Reading Score)",xlab="Score")
hist(df_eda$sqRead, main="sq(Reading Score)",xlab="Score")
hist(df_eda$inRead, main="in(Reading Score)",xlab="Score")
hist(df_eda$lgWrite, main="Log(Writing Score)",xlab="Score")
hist(df_eda$sqWrite, main="sq(Writing Score)",xlab="Score")
hist(df_eda$inWrite, main="in(Writing Score)",xlab="Score")

```
Potential transformations that may help further prepare the variables for later analysis were tested. With the expectation to normalize distribution and minimize skewness and impact of outliers, three types of transformations were tested: 1) Natural logarithm 2) Square Root 3) Inverse. The resulting plots are plotted in histograms shown below. There is no apparent improvement on the distribution of the outcome through the three transformations mentioned. Thus, orignial outcome data were chosen to be used in following statistical modeling steps. 

# Pairwise relationships

```{r}
df_num|>
  cor()|>
  corrplot(method='color',addCoef.col="grey", order = "AOE",number.cex=0.5)
```

By plotting our the pairwise correlation between variables, there is apparent linearity among the three scores. Other correlation coefficients are relatively small, indicating weak linear relationship between the variables. 

# MLR lm()

```{r MLR models}
# Build the MLR model for Math scores
model_math <- lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)
model_read <- lm(reading_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)
model_write <- lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = df_transformed)
```


## MLR - Math
```{r math}
summary(model_math)
```

### Coefficients and Significance Levels:
* Intercept (44.1006): The expected value of math_score when all other predictors are at their reference level or zero.
* gendermale (5.0855, p < 0.001): Being male is associated with an average increase of 5.0855 points in math_score compared to females, holding all else constant. This is statistically significant.
* ethnic_group: Only ethnic_groupgroup E (11.1752, p < 0.001) is significant, suggesting students in this group score higher in math compared to the reference group.
* parent_educ: The associate's degree (4.9058, p = 0.00584), bachelor's degree (6.6652, p = 0.00140), and master's degree (6.8096, p = 0.00760) are significant and associated with higher math scores compared to the reference category.
* lunch_typestandard (12.3539, p < 0.001): Students with standard lunch type score significantly higher.
* test_prepnone (-4.7717, p < 0.001): Not participating in test preparation is associated with lower math scores.
* parent_marital_status: Married (5.4805, p = 0.00075) and Widowed (7.7944, p = 0.04134) are associated with higher scores.
* practice_sport: Not significant.
* is_first_childyes: Not significant.
* nr_siblings (0.7403, p = 0.05461): A borderline significant positive association with math scores.
* transport_meansschool_bus: Not significant.
* wkly_study_hours: Studying 5-10 hours (3.5394, p = 0.00863) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
Residual Standard Error (13.52): Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* Multiple R-squared (0.3221): About 32.21% of the variability in math_score is explained by the model.
* Adjusted R-squared (0.2956): Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
F-statistic (12.18) and p-value (< 2.2e-16): The model is statistically significant, meaning it performs better than a model with no predictors.

## MLR - reading
```{r}
summary(model_read)
```
### Coefficients and Significance Levels:
* **Intercept (60.8028)**: The expected value of `reading_score` when all other predictors are at their reference level or zero.
* **gendermale (-7.6725, p < 0.001)**: Being male is associated with an average decrease of 7.6725 points in `reading_score` compared to females, holding all else constant. This is statistically significant.
* **ethnic_group**: Only `ethnic_groupgroup E` (5.9165, p = 0.013402) is significant, suggesting students in this group score higher in reading compared to the reference group.
* **parent_educ**: The `associate's degree` (4.7948, p = 0.005776), `bachelor's degree` (7.3496, p = 0.000313), and `master's degree` (8.7149, p = 0.000479) are significant and associated with higher reading scores compared to the reference category.
* **lunch_typestandard (8.4374, p < 0.001)**: Students with standard lunch type score significantly higher.
* **test_prepnone (-6.2822, p < 0.001)**: Not participating in test preparation is associated with lower reading scores.
* **parent_marital_statusmarried (5.2439, p = 0.000950)**: Children of married parents score higher.
* **practice_sport**: Not significant.
* **is_first_childyes**: Not significant.
* **nr_siblings (0.3882, p = 0.301309)**: No significant association with reading scores.
* **transport_meansschool_bus**: Not significant.
* **wkly_study_hours**: Studying 5-10 hours (2.6835, p = 0.041104) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
* **Residual Standard Error (13.2)**: Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* **Multiple R-squared (0.2709)**: About 27.09% of the variability in `reading_score` is explained by the model.
* **Adjusted R-squared (0.2425)**: Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
* **F-statistic (9.527)** and **p-value (< 2.2e-16)**: The model is statistically significant, meaning it performs better than a model with no predictors.

## MLR - writing
```{r}
summary(model_write) 
```
### Coefficients and Significance Levels:
* **Intercept (57.808758)**: The expected value of `writing_score` when all other predictors are at their reference level or zero.
* **gendermale (-9.268845, p < 0.001)**: Being male is associated with an average decrease of 9.268845 points in `writing_score` compared to females, holding all else constant. This is statistically significant.
* **ethnic_group**: `ethnic_groupgroup D` (5.010576, p = 0.016531) and `ethnic_groupgroup E` (6.018419, p = 0.008673) are significant, suggesting students in these groups score higher in writing compared to the reference group.
* **parent_educ**: `associate's degree` (6.130783, p = 0.000239), `some college` (4.338798, p = 0.010898), `bachelor's degree` (9.217680, p = 2.62e-06), and `master's degree` (11.712279, p = 1.10e-06) are significant and associated with higher writing scores compared to the reference category.
* **lunch_typestandard (9.390698, p < 0.001)**: Students with standard lunch type score significantly higher.
* **test_prepnone (-8.754351, p < 0.001)**: Not participating in test preparation is associated with lower writing scores.
* **parent_marital_statusmarried (5.246610, p = 0.000561)**: Children of married parents score higher.
* **practice_sport**: Not significant.
* **is_first_childyes**: Not significant.
* **nr_siblings (0.546033, p = 0.129340)**: No significant association with writing scores.
* **transport_meansschool_bus**: Not significant.
* **wkly_study_hours**: Studying 5-10 hours (2.802323, p = 0.026048) shows a significant positive effect.

### Residuals:
The spread of residuals suggests the errors are somewhat symmetrically distributed around the predicted values, which is a good sign for linear regression assumptions.

### Model Fit:
* **Residual Standard Error (12.65)**: Indicates the average difference between the observed values and the values predicted by the model.

### R-squared:
* **Multiple R-squared (0.3634)**: About 36.34% of the variability in `writing_score` is explained by the model.
* **Adjusted R-squared (0.3385)**: Adjusts the R-squared for the number of predictors, a better measure for models with multiple predictors.

### Statistic & p-value
* **F-statistic (14.63)** and **p-value (< 2.2e-16)**: The model is statistically significant, meaning it performs better than a model with no predictors.


## Cleaned datasets
```{r}
math_df = dplyr::select(df_num, -c(reading_score, writing_score)) 

reading_df = dplyr::select(df_num, -c(math_score, writing_score))

writing_df = dplyr::select(df_num, -c(reading_score, math_score))
```

## Step-wise + criteria-based: stepAIC()

Math Score
```{r}
math_mlr <- lm(math_score ~., data = math_df)

mathstep.model <- stepAIC(math_mlr, direction = "both", 
                      trace = FALSE)
summary(mathstep.model)
```
The step-wise-AIC model predicting math score contains gender, ethnic group, 
parent education level, lunch type, test prep, number of siblings, and weekly 
study hours.The p-values for gender, ethnic group, parent education level, 
lunch type, test prep, and weekly study hours were all < 0.05 and are therefore 
significant. Number of siblings was the only variable whose p-value > 0.05. 
The overall p-value of the model < 0.05 as well.


Reading Score
```{r}
reading_mlr <- lm(reading_score ~., data = reading_df)

readstep.model <- stepAIC(reading_mlr, direction = "both", 
                      trace = FALSE)
summary(readstep.model)
```
The step-wise-AIC model predicting reading score contains gender, ethnic group, 
parent education level, lunch type, and test prep.The p-values for all of these 
variables were < 0.05 and are therefore significant. The overall p-value of the 
model < 0.05 as well. 
  
  
Writing Score
```{r}
writing_mlr <- lm(writing_score ~., data = writing_df)

writestep.model <- stepAIC(writing_mlr, direction = "both", 
                      trace = FALSE)
summary(writestep.model)
```
The step-wise-AIC model predicting writing score contains gender, ethnic group, 
parent education level, lunch type, test prep, and weekly study hours.The 
p-values for gender, ethnic group, parent education level, lunch type, and test 
prep were all < 0.05 and are therefore significant. Weekly study hours was the 
only variable whose p-value > 0.05.The overall p-value of the model < 0.05 as 
well. 

The writing score's step-AIC model seemed to have lowest residual standard error 
out of all three scores' models. It is also interesting to note that the 
adjusted R^2 values for all three models only differed slightly from their R^2 
counterparts by about -0.01 to -0.02.

## Criteria-based approach - Adjusted R^2, Cp, and BIC

(Note: BIC has a larger penalty, leading to less predictors present within 
the model.)

Math Score
```{r}
# perform best subset selection
best_subset <- regsubsets(math_score ~ ., math_df, nvmax = 11)
results <- summary(best_subset)

# extract and plot results
tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) |>
  gather(statistic, value, -predictors) |>
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")
```
To predict math score, the adjusted R^2 statistic shows that a 7-variable is 
model is optimal, while the BIC statistic points to a 5-variable model. 
The $C_{p}$ suggests a 7-variable model as well. 

Reading Score
```{r}
best_subset <- regsubsets(reading_score ~ ., reading_df, nvmax = 11)
results <- summary(best_subset)

tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")
```
To predict reading score, the adjusted R^2 statistic shows that 6 or 7-variable 
is model is optimal, while the BIC statistic points to a 5-variable model. 
The $C_{p}$ seems to suggest a 6 or 7-variable model as well. 

Writing Score
```{r}
best_subset <- regsubsets(writing_score ~ ., writing_df, nvmax = 11)
results <- summary(best_subset)

tibble(predictors = 1:11,
       adj_R2 = results$adjr2,
       Cp = results$cp,
       BIC = results$bic) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line(show.legend = F) +
  geom_point(show.legend = F) +
  facet_wrap(~ statistic, scales = "free")
```
To predict writing score, the adjusted R^2 statistic shows that a 
7 or 8-variable is model is optimal, while the BIC statistic points to 
a 5-variable model. The $C_{p}$ suggests a 7-variable model as well. 


## LASSO approach - 

Math score:
```{r}
# Find the best lambda
math_lasso=df_transformed|>
  dplyr::select(-reading_score,-writing_score)|>
  dplyr::select(math_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(1)
cv_object = cv.glmnet(as.matrix(math_lasso[2:12]),math_lasso$math_score, lambda = lambda_seq, nfolds = 5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
math_model_lasso=glmnet(as.matrix(math_lasso[2:12]),math_lasso$math_score,lambda=cv_object$lambda.min)
coef(math_model_lasso)
```

Reading score:

```{r}
read_lasso=df_transformed|>
  dplyr::select(-math_score,-writing_score)|>
  dplyr::select(reading_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(2)
cv_object = cv.glmnet(as.matrix(read_lasso[2:12]),read_lasso$reading_score, lambda = lambda_seq, nfolds =5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
read_model_lasso=glmnet(as.matrix(read_lasso[2:12]),read_lasso$reading_score,lambda=cv_object$lambda.min)
coef(read_model_lasso)
```

Writing score:

```{r}
write_lasso=df_transformed|>
  dplyr::select(-reading_score,-math_score)|>
  dplyr::select(writing_score,everything())

lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(2)
cv_object = cv.glmnet(as.matrix(write_lasso[2:12]),write_lasso$writing_score, lambda = lambda_seq, nfolds =5)

tibble(lambda = cv_object$lambda,
       mean_cv_error = cv_object$cvm) |>
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# Use the best lambda to model
write_model_lasso=glmnet(as.matrix(write_lasso[2:12]),write_lasso$writing_score,lambda=cv_object$lambda.min)
coef(write_model_lasso)
```

